* [OpenAI、学習する方法を学習するメタラーニングアルゴリズム「Reptile」発表。ブラウザ上で試せるインタラクティブデモあり | Seamless](http://shiropen.com/2018/03/12/33032)
* [Reptile:  a Scalable Metalearning Algorithm(論文)](https://arxiv.org/pdf/1803.02999.pdf)
  * 著者: Alex Nichol、John Schulman(OpenAI)
  * [Github ソースコード](https://github.com/openai/supervised-reptile)

なんだか面白そうなので論文を読んでまとめてみました。

# ちょー忙しい人用まとめ

* Reptile はパラメータ初期化に着目したメタラーニング(学習する方法を学習する)手法
* 人間のベイズ推定が元アイデア
* あ

# 論文まとめ

## Abstract

* Reptile は メタラーニング手法
* パラメータ初期化を効率化している
* MAML と違って最適化手法を変更する必要がない
  * 大量の更新ステップが必要な最適化問題に適している
  * MAML よくわかってません
*

## Introduction

* 人間とスクラッチから学習するアルゴリズムを比較するのは不平等では？
  * Atari game だと人間なら初心者でも 15分後には進捗出せるけど、 double-dueling-DQL[WSH+15]だとその 1000 倍以上必要とする
  * 人間は DNA とかで予め fine-tuninig されてるやん？
  * Tenenbaum とその協力者曰く、人間の学習が速いのはベイズ推定してるからとのこと
* メタラーニングのアプローチ
  * 学習アルゴリズムを RNN の重みに変換して RNN を学習する
    *
  * ネットワークの初期化について学習する
    * Reptile はこれ
    * 以前の pre-training アプローチは fine-tuning につながる初期化を保証していなかった
    * MAML[FAL17] では初期化を重視してパフォーマンスを最適化
      * 最適化の process を変えていく
      * そのためテスト時に勾配ステップが膨大なときはパフォーマンスが良くない
      * それに対処すべく著者は first-order MAML を提案している。
        * これは 2次の微分項を無視している
*

## Algorithm

* MAML は NN モデルのパラメータ初期化を学習する

```math


```


## Case Study: One-Dimensional Sine Wave Regression

* タスク $\tau = (a,b)$ は振幅 $a$ と 位相 $\phi$ (正弦波関数 $f_{\tau}(x) = a \sin(x+b)$) で定義される。$a$、$b$ は $a \sim U([0.1, 5.0])$ と $b \sim U([0, 2\pi])$ のように生成される。
* $p$ 個の点をサンプリングする $x_1, x_2, ..., x_p \sim U([-5,5])$
* 学習器は $(x_1, y_1),(x_2,y_2),...,(x_p,y_p)$ を見て $f(x)$ を予測する
* 区間 $[-5, 5]$ での損失 である $l_2$ 誤差は下記の式で計算する
  * 今回は 50 個の等間隔な点 $x$ を使って下記の式を近似計算する
```math
\displaystyle L_{\tau}(f) = \int^5_{-5} \mathrm{d}x || f(x) - f_{\tau}(x) ||^2
```

##  Analysis

###

###


## Experiments


## Discussion
